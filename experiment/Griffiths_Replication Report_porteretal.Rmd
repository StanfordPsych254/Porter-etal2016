---
title: "Replication of Porter et al. 2016 by Griffiths (2016, Psychological Science)"
author: "Camilla Griffiths (camillag@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
 
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

This replication report tested study 1a from Porter et al, 2016 "Inferring Identity From Language: Linguistic Intergroup Bias Informs Social Categorization". The package of studies in this paper tests whether people are able to infer the social identity of a speaker based on their language-use, specifically their use of Linguistic Intergroup Bias (LIB): the use of abstract language to describe in-group targets' desirable behaviors and concrete language to describe their undesirable behaviors (favorable LIB), and the use of concrete language for out-group targets' desirable behaviors and abstract language for their undesirable behaviors (unfavorable LIB). The paper includes 4 studies, each of which manipulates a *communicator's* use of either favorable or unfavorable LIB and measures participants' social categorization of the communicator. In study 1a, it tests the hypothesis that people can infer the social identity (in this case, poltiical orientation) of a communicator based on the conreteness or abstractness of their language (i.e. LIB) about a target. 


##Methods

###Power Analysis

The original analysis appears to be a two-sample t-test, and using their original sample size and reported effect size I performed a post-hoc power analysis, which yielded 60% percent power. To achieve the desired 80% power in this replication while maintaining the effect size of d=0.62, I increased the sample from the original 88 to 126.  Given that the sample is going to be collected on Mturk as it was in the original study, I think that this increase in sample size to obtain 80% power is feasible. 

Note: the authors did not specify which type of t-test they performed, but I intuited it was a two-sample t-test based on their language and the design of the study. This is the only language in the results section for the primary DV of interest: "participants in the favorable-LIB condition were significantly more likely to believe that the communicator was a Democrat, and thus shared a party affiliation with the target, than were participants in the unfavorable-LIB condition, t(86) = 2.89, p = .005, d = 0.62."

###Planned Sample

Planned sample, as stated above, is 126 participants for a two condition, within-participant study design. 

###Materials

"Participants completed all tasks on a computer. They were asked to read a passage and then respond to questions. The beginning of the passage was the same for all participants: “Imagine that someone is communicating with you about a man named Peter. Peter is American, has an interest in politics, and voted for Barack Obama.” This information was intended to subtly imply that Peter (the target) was a Democrat. In the second part of the passage, participants were provided with the communicator’s description of Peter’s helpful and rude behaviors." 

These materials were offered in full in the SI [found here](http://journals.sagepub.com/doi/suppl/10.1177/0956797615612202/suppl_file/suppl-material.pdf). 

###Procedure	

"In the favorable-LIB condition, Peter’s helping behavior was described abstractly (e.g., “[Peter] is someone who stands up for the interests of others”), and his rude behavior was described concretely (e.g., “Peter said something rude to another person recently”). In the unfavorable-LIB condition, Peter’s helping behavior was described concretely (e.g., “Peter helped another person, even when it did not benefit him”), and his rude behavior was described abstractly (e.g., “[Peter] is cold and unfriendly”). After reading the passage, participants were asked to assess the likelihood that the communicator was either a Democrat or a Republican. Ratings were made on a 7-point scale, anchored by 1, definitely a Republican, and 7, definitely a Democrat. As a check of the effectiveness of the LIB manipulation, we asked participants to estimate the percentage of future situations in which Peter was likely to be helpful and the percentage of future situations in which he was likely to be rude (Semin & de Poot, 1997). Finally, participants completed a demographic questionnaire that asked their gender, their political- party affiliation, and the degree to which they endorsed liberal and conservative beliefs (on 7-point scales ranging from 1, strongly disagree, to 7, strongly agree)." 

This procedure was precisely followed with the exception of the exact wording of the dempgraphic questions, political party affiliation, and political beliefs. I wrote the language for these questions myself, and borrowed the political beliefs questions from Pew political opinion poll questions that were highly rated as liberal or conservative. 

###Analysis Plan

The key analysis is as follows: 

I will conduct the same manipulation checks that were done in the original study: calculating raw mean ratings of Peter (the target) as rude and helpful as well as a regression testing the likelihood of rating Peter as rude or helpful based on condition, and extracting t-statistics and effect sizes for each of these regressions. 

After the manipulation check anlayses, the key analysis of interest will be the regression predicting identification of communicator by LIB condition.  I will also examine the same regression moderated by the participants' own political orientation, just as the authors did. In both cases, I will calculate the effect sizes for each regression and will be looking to replicate the t-statistic, p-value, and effect sizes. 


###Differences from Original Study

I wrote the language for the demographics questions myself, and borrowed four items for the political beliefs questions from Pew political opinion poll questions. I do not expect this difference to impact the results in any way. 

### Link to current version of the experiment 

https://stanforduniversity.qualtrics.com/SE/?SID=SV_8BT3uDEjxT0UBIF 



### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results

```{r setup, include=FALSE}
library("tidyverse")
library("effsize")
library("magrittr")
library("dplyr")
library("broom")
library("stringr")
library("knitr")
```

### Data preparation

Importing data and creating Favorable (LIB) and Unfavorable (ULIB) condition variables. 

```{r include=F}
pilotA= read_csv('/Users/camilla/Documents/Winter_17/Psych254/Porter-etal2016/experiment/pilot1data.csv')

pilotA = pilotA %>%
  slice(-(1:2)) %>%
  mutate(condition= ifelse(is.na(LIB_DV) , "ULIB", "LIB"))
str(pilotA$condition)
```

### Confirmatory analysis 

##Manipulation Check

From the paper (re: LIB manipulation checks): 

"As expected, participants in
the favorable-LIB condition believed that Peter was more
likely to be helpful in the future (M = 70.29%, SD = 23.58)
than did participants in the unfavorable-LIB condition
(M = 57.83%, SD = 24.08), t(86) = 2.45, p = .016, d = 0.53.
Similarly, participants in the favorable-LIB condition indicated
that Peter was less likely to be rude in the future
(M = 33.67%, SD = 25.48) compared with participants in
the unfavorable-LIB condition (M = 53.93%, SD = 25.22),
t(86) = 3.73, p < .001, d = 0.80."

```{r manipulation checks}

pilotA$MCfuture_helpful_1=as.numeric(pilotA$MCfuture_helpful_1)
pilotA$MCfuture_rude_1=as.numeric(pilotA$MCfuture_rude_1)
pilotA$condition=as.factor(pilotA$condition)

pilotA %>%
  group_by(condition) %>%
  summarise(meanhelp=mean(MCfuture_helpful_1)) 

pilotA %>%
  group_by(condition) %>%
  summarise(meanrude=mean(MCfuture_rude_1))

mc_helpful=lm(MCfuture_rude_1 ~ condition, data=pilotA)
mc_help_table <- tidy(mc_helpful)
mc_help_table %>% print(digits = 3)
kable(mc_help_table, digits = 3,
      col.names = c("Param", "B", "SE", "t", "p"))
cohen.d(pilotA$MCfuture_rude_1 ~ pilotA$condition, conf.level=0.95)

mc_rude=lm(MCfuture_helpful_1 ~ condition, data=pilotA)
mc_rude_table <- tidy(mc_rude)
mc_rude_table %>% print(digits = 3)   
kable(mc_rude_table, digits = 3,
      col.names = c("Param", "B", "SE", "t", "p"))
cohen.d(pilotA$MCfuture_helpful_1 ~ pilotA$condition, conf.level=0.95)


```

##Key Statistical Analysis

From the paper (re: main DV analysis): 

"Social category inference. The primary dependent
measure was participants’ inferences regarding the communicator’s
political affiliation. As predicted, participants
in the favorable-LIB condition were significantly more
likely to believe that the communicator was a Democrat,
and thus shared a party affiliation with the target, than
were participants in the unfavorable-LIB condition,
t(86) = 2.89, p = .005, d = 0.62 (Fig. 1). This difference
was not moderated by participants’ self-reported political-
party affiliation or ideological endorsement (ps > .18).
Our findings suggested initial support for our hypothesis
that individuals can infer a communicator’s social identity
from his or her language, regardless of their own social
identity"

For this analysis, I create a 'social identity inference' variable (peterID) as the primary outcome variable. I then run a linear regression predicting peterID by LIB condition to produce the main statistics of interest: the t-statistic, p-value, and cohen's d of this effect. This analysis answers the question: does LIB condition impact people's perceptions of Peter's identity? (1=definitely a democrat, 7=definitely a republican). Just as the authors did, I also test for moderation of this effect by the participant's own political orientation. 

```{r social category inference - MAIN DV}
pilotA[is.na(pilotA)] = ''
pilotA=pilotA%>%
  mutate(peterID=paste(LIB_DV, ULIB_DV)) %>%
  mutate(peterID=as.numeric(peterID)) %>%
  mutate(pol_orient=as.numeric(pol_orient))


polID=lm(peterID ~ condition, data=pilotA)
polID_table <- tidy(polID)
polID_table %>% print(digits = 3)
kable(polID_table, digits = 3,
      col.names = c("Param", "B", "SE", "t", "p"))
cohen.d(pilotA$peterID ~ pilotA$condition, conf.level=0.95)

#summary(lm(peterID ~ condition + pol_orient, data=pilotA)) #commenting this out now because there's not enough data in pilotA to run this regression. 
```

```{r replication plot from original study}
pilotA$peterID=as.integer(pilotA$peterID)
pilotA$condition=as.factor(pilotA$condition)
 
sem = function(x)                    
{sqrt(var(x)/length(x))}            

agg <- pilotA %>% group_by(condition) %>% 
      summarise(mean = mean(peterID,na.rm=T), 
                se = sem(as.numeric(peterID)), 
                upper = mean + 1.96*se, 
                lower = mean - 1.96*se)

ggplot(agg,aes(x=condition,y=mean,fill=condition)) + 
geom_bar(stat="identity", position="dodge") + 
theme_classic() +
geom_errorbar( aes( ymax=upper, ymin=lower ),
                           width   =0.5,
                          linetype="solid",
                          position="dodge")+
  ylab("Mean Political Category ID") + 
  xlab("LIB Condition")
```


Original Plot for Study 1a can be seen below


![](https://raw.githubusercontent.com/StanfordPsych254/Porter-etal2016/master/experiment/original_plot.png)
 


## Discussion

### Summary of Replication Attempt

<!-- Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result --> 

### Commentary

<!-- #Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.-->
