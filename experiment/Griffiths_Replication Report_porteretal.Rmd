---
title: "Replication of Porter et al. 2016 by Griffiths (2016, Psychological Science)"
author: "Camilla Griffiths (camillag@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
 
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

This replication tested study 1a from Porter et al, 2016 "Inferring Identity From Language: Linguistic Intergroup Bias Informs Social Categorization". The package of studies in this paper tests whether people are able to infer the social identity of a speaker based on their language-use, specifically their use of Linguistic Intergroup Bias (LIB): the use of abstract language to describe in-group targets' desirable behaviors and concrete language to describe their undesirable behaviors (favorable LIB), and the use of concrete language for out-group targets' desirable behaviors and abstract language for their undesirable behaviors (unfavorable LIB). The paper includes 4 studies, each of which manipulates a *communicator's* use of either favorable or unfavorable LIB and measures participants' social categorization of the communicator. In study 1a, it tests the hypothesis that people can infer the social identity (in this case, poltiical orientation) of a communicator based on the conreteness or abstractness of their language (i.e. LIB) about a target. 


##Methods

###Power Analysis

The original analysis appears to be a two-sample t-test, and using their original sample size and reported effect size I performed a post-hoc power analysis, which yielded 60% percent power. To achieve the desired 80% power in this replication while maintaining the effect size of d=0.62, I increased the sample from the original 88 to 126.  Given that the sample is going to be collected on Mturk as it was in the original study, I think that this increase in sample size to obtain 80% power is feasible. 

Note: the authors did not specify which type of t-test they performed, but I intuited it was a two-sample t-test based on their language and the design of the study. This is the only language in the results section for the primary DV of interest: "participants in the favorable-LIB condition were significantly more likely to believe that the communicator was a Democrat, and thus shared a party affiliation with the target, than were participants in the unfavorable-LIB condition, t(86) = 2.89, p = .005, d = 0.62."

###Planned Sample

Planned sample, as stated above, is 126 participants for a two condition, within-participant study design. 

###Materials

"Participants completed all tasks on a computer. They were asked to read a passage and then respond to questions. The beginning of the passage was the same for all participants: “Imagine that someone is communicating with you about a man named Peter. Peter is American, has an interest in politics, and voted for Barack Obama.” This information was intended to subtly imply that Peter (the target) was a Democrat. In the second part of the passage, participants were provided with the communicator’s description of Peter’s helpful and rude behaviors." 

These materials were offered in full in the SI [found here](http://journals.sagepub.com/doi/suppl/10.1177/0956797615612202/suppl_file/suppl-material.pdf). 

###Procedure	

"In the favorable-LIB condition, Peter’s helping behavior was described abstractly (e.g., “[Peter] is someone who stands up for the interests of others”), and his rude behavior was described concretely (e.g., “Peter said something rude to another person recently”). In the unfavorable-LIB condition, Peter’s helping behavior was described concretely (e.g., “Peter helped another person, even when it did not benefit him”), and his rude behavior was described abstractly (e.g., “[Peter] is cold and unfriendly”). After reading the passage, participants were asked to assess the likelihood that the communicator was either a Democrat or a Republican. Ratings were made on a 7-point scale, anchored by 1, definitely a Republican, and 7, definitely a Democrat. As a check of the effectiveness of the LIB manipulation, we asked participants to estimate the percentage of future situations in which Peter was likely to be helpful and the percentage of future situations in which he was likely to be rude (Semin & de Poot, 1997). Finally, participants completed a demographic questionnaire that asked their gender, their political- party affiliation, and the degree to which they endorsed liberal and conservative beliefs (on 7-point scales ranging from 1, strongly disagree, to 7, strongly agree)." 

This procedure was precisely followed with the exception of the exact wording of the dempgraphic questions, political party affiliation, and political beliefs. I wrote the language for these questions myself, and borrowed the political beliefs questions from Pew political opinion poll questions that were highly rated as liberal or conservative. 

###Analysis Plan

The key analysis is as follows: 

I will conduct the same manipulation checks that were done in the original study: calculating raw mean ratings of Peter (the target) as rude and helpful as well as a regression testing the likelihood of rating Peter as rude or helpful based on condition, and extracting t-statistics and effect sizes for each of these regressions. 

After the manipulation check anlayses, the key analysis of interest will be the regression predicting identification of communicator by LIB condition.  I will also examine the same regression moderated by the participants' own political orientation, just as the authors did. In both cases, I will calculate the effect sizes for each regression and will be looking to replicate the t-statistic, p-value, and effect sizes. 


###Differences from Original Study

I wrote the language for the demographics questions myself, and borrowed four items for the political beliefs questions from Pew political opinion poll questions. I do not expect this difference to impact the results in any way. 

### Link to current version of the experiment 

https://stanforduniversity.qualtrics.com/SE/?SID=SV_8BT3uDEjxT0UBIF 



#### Actual Sample
The final sample was 119 participants - 5 participants submitted their HITs on Mturk but did not complete the survey on Qualtrics, and one person got to the end of the survey in Qualtrics but did not complete any of the survey responses, so they were expluded. Therefore, the intended sample size of 126 was not achieved. The sample was 53% female and 82% White. 

#### Differences from pre-data collection methods plan
 None


##Results

```{r setup, include=FALSE}
library("tidyverse")
library("effsize")
library("magrittr")
library("dplyr")
library("broom")
library("stringr")
library("knitr")
```

### Data preparation

Importied data and created Favorable (LIB) and Unfavorable (ULIB) condition variables. 

```{r include=F}
d= read_csv('/Users/camilla/Documents/Winter_17/Psych254/Porter-etal2016/experiment/254_porter_et_al_replication.csv')

d = d %>%
  slice(-(1:2)) %>%
  mutate(condition= ifelse(is.na(LIB_DV) , "ULIB", "LIB"))%>%
  filter(V10==1) #removing the one participant who did not finish the study (finished=1, incomplete response=0)
str(d$condition)

```

### Confirmatory analysis 

### Manipulation Check

From the paper (re: LIB manipulation checks): 

"As expected, participants in
the favorable-LIB condition believed that Peter was more
likely to be helpful in the future (M = 70.29%, SD = 23.58)
than did participants in the unfavorable-LIB condition
(M = 57.83%, SD = 24.08), t(86) = 2.45, p = .016, d = 0.53.
Similarly, participants in the favorable-LIB condition indicated
that Peter was less likely to be rude in the future
(M = 33.67%, SD = 25.48) compared with participants in
the unfavorable-LIB condition (M = 53.93%, SD = 25.22),
t(86) = 3.73, p < .001, d = 0.80."

```{r manipulation checks}

d$MCfuture_helpful_1=as.numeric(d$MCfuture_helpful_1)
d$MCfuture_rude_1=as.numeric(d$MCfuture_rude_1)
d$condition=as.factor(d$condition)

contrasts(d$condition)
d %>%
  group_by(condition) %>%
  summarise(meanhelp=mean(MCfuture_helpful_1))

d %>%
  group_by(condition) %>%
  summarise(meanrude=mean(MCfuture_rude_1))

mc_helpful=lm(MCfuture_helpful_1 ~ condition, data=d)
mc_help_table <- tidy(mc_helpful)
mc_help_table %>% print(digits = 3)
kable(mc_help_table, digits = 3,
      col.names = c("Param", "B", "SE", "t", "p"))
cohen.d(d$MCfuture_helpful_1 ~ d$condition, conf.level=0.95)

mc_rude=lm(MCfuture_rude_1 ~ condition, data=d)
mc_rude_table <- tidy(mc_rude)
mc_rude_table %>% print(digits = 3)   
kable(mc_rude_table, digits = 3,
      col.names = c("Param", "B", "SE", "t", "p"))
cohen.d(d$MCfuture_rude_1 ~ d$condition, conf.level=0.95)


```

###Manipulation Check Replication results: 

Participants in the favorable-LIB condition believed that Peter was more likely to be helpful in the future (*M=68.36%*) than did participants in the unfavorable-LIB condition (*M=56.14%*), *t(117)= 3.23, p<0.001, d=0.64*.

Participants in the favorable-LIB condition believed that Peter was less likely to be rude in the future (*M=32.9*) than did participants in the unfavorable-LIB condition (*M=54.18*), *t(117)=5.23, p<0.001, d=0.96*.

Successful replication of their manipulation checks such that people interpreted the target, Peter, in the way that was intended in each LIB condition. 

##Key Statistical Analysis

From the paper (re: main DV analysis): 

"Social category inference. The primary dependent
measure was participants’ inferences regarding the communicator’s
political affiliation. As predicted, participants
in the favorable-LIB condition were significantly more
likely to believe that the communicator was a Democrat,
and thus shared a party affiliation with the target, than
were participants in the unfavorable-LIB condition,
t(86) = 2.89, p = .005, d = 0.62 (Fig. 1). This difference
was not moderated by participants’ self-reported political-
party affiliation or ideological endorsement (ps > .18).
Our findings suggested initial support for our hypothesis
that individuals can infer a communicator’s social identity
from his or her language, regardless of their own social
identity"

For this analysis, I create a 'social identity inference' variable (peterID) as the primary outcome variable. I then run a linear regression predicting peterID by LIB condition to produce the main statistics of interest: the t-statistic, p-value, and cohen's d of this effect. This analysis answers the question: does LIB condition impact people's perceptions of Peter's identity? (*1=definitely a democrat, 7=definitely a republican*). Just as the authors did, I also test for moderation of this effect by the participant's own political orientation. 

```{r social category inference - MAIN DV}
d[is.na(d)] = ''
d=d%>%
  mutate(peterID=paste(LIB_DV, ULIB_DV)) %>%
  mutate(peterID=as.numeric(peterID)) %>%
  mutate(pol_orient=as.numeric(pol_orient))


polID=lm(peterID ~ condition, data=d)
polID_table <- tidy(polID)
polID_table %>% print(digits = 3)
kable(polID_table, digits = 3,
      col.names = c("Param", "B", "SE", "t", "p"))
cohen.d(d$peterID ~ d$condition, conf.level=0.95)

summary(lm(peterID ~ condition + pol_orient, data=d)) 

```

#Primary DV replication results: 

The primary dependent measure appears to replicate, with participants in the favorable-LIB condition being significantly more likely to identify the communicator as a Democrat (thus sharing political ID with the target, Peter) than participants in the unfavorable-LIB condition, *t(117)=3.93, p<0.001, d=0.72* and it looks like our larger sample size yielded a larger effect size in our replication than in the original study. 

This difference between LIB conditions, as in the original results, was not moderated by participants' self-reported political-party affiliation (*p=0.62*). 

```{r replication plot from original study}
d$peterID=as.integer(d$peterID)
d$condition=as.factor(d$condition)
 
sem = function(x)                    
{sqrt(var(x)/length(x))}            

agg <- d %>% group_by(condition) %>% 
      summarise(mean = mean(peterID,na.rm=T), 
                se = sem(as.numeric(peterID)), 
                upper = mean + 1.96*se, 
                lower = mean - 1.96*se)

ggplot(agg,aes(x=condition,y=mean,fill=condition)) + 
geom_bar(stat="identity", position="dodge") + 
theme_classic() +
scale_fill_brewer(palette="Set1")  +
geom_errorbar( aes( ymax=upper, ymin=lower ),
                           width   =0.3,
                          linetype="solid",
                          position="dodge")+
  ylab("Mean Political Category ID") + 
  xlab("LIB Condition")
```


###Original Plot for Study 1a can be seen below:


![](https://raw.githubusercontent.com/StanfordPsych254/Porter-etal2016/master/experiment/original_plot.png)
 


## Discussion

### Summary of Replication Attempt

This replication appears to be a success! Both the manipulation checks and the primary DV analyses in this replication of study 1a produced the same results as the original study: finding that participants are more likely to infer that a communicator shares political identification with a target when they use Favorable LIB language than when they use Unfavorable LIB language. The only inconsistency is in the mean ratings of the communicator's political identity, with participants in this replication rating the communicator as overwhelmingly more 'democrat' across both conditions than in the original study. That is, in the original study, ratings were between 3 and 4.5 on a 7 point scale, whereas in this replication the mean rating was aroung 5.5. The paper does not include a mean rating value, so I am inferring their mean ratings from the plot above. Given that the ratings are stronger in both conditions, I do not think this is an indication of a stronger effect of LIB condition, but rather a reflection of greater political polarization in the U.S. right now. So, the fact that the communicator said something nice about the target *at all* may have made participants more likely to categorize them as a Democrat. 


### Commentary

It is encouraging that this study was able to replicate because it tests the foundational notion that the rest of the paper relies on - that one can infer social identity from subtle features in language. 
